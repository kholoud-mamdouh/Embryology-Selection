{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIF1yqxj3pKj",
        "outputId": "876bbc14-6a90-4c98-afdc-95ae7620a571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "dTMdM2UZ6mLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the image dimensions and batch size\n",
        "img_rows, img_cols, channels = 28, 28, 3\n",
        "batch_size = 64\n",
        "latent_dim = 100\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "roeSyU5dyUQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_files\n",
        "\n",
        "train_dataset = load_files('/content/drive/MyDrive/data/train')\n",
        "test_dataset = load_files('/content/drive/MyDrive/data/test')\n"
      ],
      "metadata": {
        "id": "25Q5Zl0b4oHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = train_dataset.filenames\n",
        "train_labels = train_dataset.target\n",
        "\n",
        "test_images = test_dataset.filenames\n",
        "test_labels = test_dataset.target"
      ],
      "metadata": {
        "id": "6fHBUSux7p0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.utils as image\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "# Preprocess the images\n",
        "train_images = [image.img_to_array(image.load_img(img, target_size=(28, 28))) for img in train_images]\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "test_images = [image.img_to_array(image.load_img(img, target_size=(28, 28))) for img in test_images]\n",
        "test_images = np.array(test_images)\n",
        "# Preprocess the labels\n",
        "nClasses=2\n",
        "train_labels_c = to_categorical(train_labels,num_classes=nClasses)\n",
        "test_labels_c = to_categorical(test_labels,num_classes=nClasses)"
      ],
      "metadata": {
        "id": "bAOrsToD7x3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageDataGenerator to read and augment the images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "EYJvwrWz5Un9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the training and testing datasets\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/data/train\",\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/data/test\",\n",
        "    target_size=(img_rows, img_cols),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPLYOALM8wx2",
        "outputId": "b9105ef7-6055-4878-8b39-9c47bb342ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 84 images belonging to 2 classes.\n",
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_rows, img_cols, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=test_generator.samples // batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCXW_hA8-V3D",
        "outputId": "e0451383-9b24-462f-f122-b0acc1a34fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-fc6408bbde99>:28: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6961 - accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 552ms/step - loss: 0.6831 - accuracy: 0.5938\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 0.6728 - accuracy: 0.7500\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.6890 - accuracy: 0.4531\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.7041 - accuracy: 0.4531\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.6617 - accuracy: 0.6500\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 554ms/step - loss: 0.7124 - accuracy: 0.4531\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.6695 - accuracy: 0.5500\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 0.6948 - accuracy: 0.4375\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.7207 - accuracy: 0.4500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa3d246bb0>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "\n",
        "img_rows, img_cols, channels = 28, 28, 3\n",
        "batch_size = 64\n",
        "latent_dim = 100\n",
        "num_classes = 2\n",
        "\n",
        "# Build the generator\n",
        "generator = Sequential()\n",
        "\n",
        "generator.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
        "generator.add(Reshape((7, 7, 128)))\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "generator.add(Activation(\"relu\"))\n",
        "generator.add(UpSampling2D())\n",
        "generator.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "generator.add(BatchNormalization(momentum=0.8))\n",
        "generator.add(Activation(\"relu\"))\n",
        "generator.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
        "generator.add(Activation(\"tanh\"))\n",
        "\n",
        "# Build the discriminator\n",
        "discriminator = Sequential()\n",
        "\n",
        "discriminator.add(Conv2D(128, kernel_size=3, strides=2, input_shape=(img_rows, img_cols, channels), padding=\"same\"))\n",
        "discriminator.add(LeakyReLU(alpha=0.01))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "discriminator.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "discriminator.add(BatchNormalization(momentum=0.8))\n",
        "discriminator.add(LeakyReLU(alpha=0.01))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "discriminator.add(BatchNormalization(momentum=0.8))\n",
        "discriminator.add(LeakyReLU(alpha=0.01))\n",
        "discriminator.add(Dropout(0.25))\n",
        "discriminator.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "discriminator.add(BatchNormalization(momentum=0.8))\n",
        "discriminator.add(LeakyReLU(alpha=0.01))\n",
        "\n"
      ],
      "metadata": {
        "id": "0Pm7FQmrGI6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "class GeneratorNet(nn.Module):\n",
        "  def __init__(self, latent_dim, img_size):\n",
        "    super().__init__()\n",
        "    # Define the layers of the generator network\n",
        "    self.x1 = nn.Linear(latent_dim, 128)\n",
        "    self.x2 = nn.Linear(128, 256)\n",
        "    self.x3 = nn.Linear(256, img_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Define the forward pass of the generator network\n",
        "    x = self.x1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.x2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.x3(x)\n",
        "    return x\n",
        "\n",
        "class DiscriminatorNet(nn.Module):\n",
        "  def __init__(self, img_size):\n",
        "    super().__init__()\n",
        "    # Define the layers of the discriminator network\n",
        "    self.z1 = nn.Linear(img_size, 128)\n",
        "    self.z2 = nn.Linear(128, 64)\n",
        "    self.z3 = nn.Linear(64, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Define the forward pass of the discriminator network\n",
        "    x = self.z1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.z2(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.z3(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "KKKBLdgaITjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the GAN model\n",
        "class GAN(nn.Module):\n",
        "  def __init__(self, latent_dim, img_size):\n",
        "    super().__init__()\n",
        "    self.generator = GeneratorNet(latent_dim, img_size)\n",
        "    self.discriminator = DiscriminatorNet(img_size)\n"
      ],
      "metadata": {
        "id": "LtNpdu6YJIGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the GAN model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "gan = tf.keras.Sequential()\n",
        "gan.add(generator)\n",
        "gan.add(discriminator)\n",
        "\n",
        "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Freeze the weights of the discriminator\n",
        "discriminator.trainable = False\n",
        "\n",
        "# Connect the generator and discriminator to create the GAN model\n",
        "gan = keras.Sequential([generator, discriminator])\n",
        "\n",
        "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n"
      ],
      "metadata": {
        "id": "JQE11TPrvYij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the GAN model\n",
        "for epoch in range(200):\n",
        "    # Generate a batch of random noise\n",
        "    noise = np.random.rand(128, 100)\n",
        "\n",
        "    # Generate a batch of fake samples\n",
        "    fake_samples = generator.predict(noise)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffHvjP70586v",
        "outputId": "8061aacb-2ae7-45d0-8f7a-59b606998c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 201ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 180ms/step\n",
            "4/4 [==============================] - 1s 347ms/step\n",
            "4/4 [==============================] - 1s 324ms/step\n",
            "4/4 [==============================] - 1s 332ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 284ms/step\n",
            "4/4 [==============================] - 1s 205ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 195ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 193ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 180ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 178ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 268ms/step\n",
            "4/4 [==============================] - 1s 351ms/step\n",
            "4/4 [==============================] - 1s 370ms/step\n",
            "4/4 [==============================] - 1s 351ms/step\n",
            "4/4 [==============================] - 1s 351ms/step\n",
            "4/4 [==============================] - 1s 346ms/step\n",
            "4/4 [==============================] - 1s 211ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 296ms/step\n",
            "4/4 [==============================] - 1s 291ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 193ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 195ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 180ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 196ms/step\n",
            "4/4 [==============================] - 1s 200ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 180ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 196ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 197ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 193ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 180ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 197ms/step\n",
            "4/4 [==============================] - 1s 193ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 190ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 186ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 182ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 200ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 179ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 183ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 189ms/step\n",
            "4/4 [==============================] - 1s 199ms/step\n",
            "4/4 [==============================] - 1s 184ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 188ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 179ms/step\n",
            "4/4 [==============================] - 1s 194ms/step\n",
            "4/4 [==============================] - 1s 187ms/step\n",
            "4/4 [==============================] - 1s 192ms/step\n",
            "4/4 [==============================] - 1s 197ms/step\n",
            "4/4 [==============================] - 1s 193ms/step\n",
            "4/4 [==============================] - 1s 181ms/step\n",
            "4/4 [==============================] - 1s 191ms/step\n",
            "4/4 [==============================] - 1s 177ms/step\n",
            "4/4 [==============================] - 1s 185ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gan.save('gan.h5')"
      ],
      "metadata": {
        "id": "SDNTKRRioWl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}